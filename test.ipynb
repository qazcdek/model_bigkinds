{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qazcde/miniconda3/envs/rag_infovisor/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# (save)mongoDB => documentDB \n",
    "# (load)documentDB => mongoDB\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "from config import MILVUS_DB_FR, MILVUS_USER, MILVUS_PASSWORD, MILVUS_URI, MILVUS_TOKEN, already_milvus\n",
    "\n",
    "# create milvus\n",
    "from pymilvus import connections, utility, MilvusClient, Partition, Collection\n",
    "from pymilvus import Collection, DataType, FieldSchema, CollectionSchema\n",
    "from language_model.embed_model import embed_helper\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "milvus_db_fr = MILVUS_DB_FR\n",
    "milvus_user = MILVUS_USER\n",
    "milvus_password = MILVUS_PASSWORD\n",
    "milvus_uri = MILVUS_URI\n",
    "milvus_token = MILVUS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# documents_FR, chunks_FR\n",
    "def creat_milvus_collection(collection_name, milvus_db=milvus_db_fr, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token, dim=768, overwrite=False, **kwargs):\n",
    "    #assert collection_name in collection_list, f\"collection name must be {collection_list}\"\n",
    "    assert \"chunks\" in collection_name or \"documents\" in collection_name, f\"collection name must contain 'chunks' or 'documents'\"\n",
    "    # milvus args: collection name, uri, token\n",
    "    milvus_settings = {\"collection_name\":collection_name, \"milvus_uri\":milvus_uri, \"milvus_token\":milvus_token}\n",
    "    if not milvus_token:\n",
    "        milvus_token = f\"{milvus_user}:{milvus_password}\"\n",
    "    try:\n",
    "        connections.connect(\n",
    "            uri=milvus_uri,\n",
    "            token=milvus_token)\n",
    "        print(f\"Connect to DB: Success\")\n",
    "    except:\n",
    "        print(f\"Failed to connect, please check MILVUS URI/TOKEN.\")\n",
    "        sys.exit()\n",
    "    \n",
    "    check_collection = utility.has_collection(collection_name)\n",
    "    # if collection already exist, overwrite or quit\n",
    "    \n",
    "    if check_collection:\n",
    "        if overwrite:\n",
    "            drop_result = utility.drop_collection(collection_name)\n",
    "        else:\n",
    "            print(f\"Collection named '{collection_name}' already exists, please set overwrite arg True or select different collection name.\")\n",
    "            connections.disconnect(\"default\")\n",
    "            sys.exit()\n",
    "\n",
    "    print(\"start to create schema!\")\n",
    "    # create a collection with customized primary field: book_id_field\n",
    "    if 'chunks' in collection_name:\n",
    "        id_field = FieldSchema(name=\"id\", dtype=DataType.VARCHAR, is_primary=True, max_length=32, description=\"customized primary id\")\n",
    "        embedding_field = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=dim, description=\"vector embeddings for text\")\n",
    "        metadata_field = FieldSchema(name=\"metadata\", dtype=DataType.JSON)\n",
    "        text_field = FieldSchema(name=\"text\", dtype=DataType.VARCHAR, description=\"raw text\", max_length=8192)\n",
    "\n",
    "        schema = CollectionSchema(fields=[id_field, embedding_field, metadata_field, text_field], description=\"collection for Federal Register documents (chunks)\")\n",
    "        print(f\"Creating example collection: {collection_name}\")\n",
    "        collection = Collection(name=collection_name, schema=schema)\n",
    "        connections.disconnect(\"default\")\n",
    "    \n",
    "    elif 'documents' in collection_name:\n",
    "        id_field = FieldSchema(name=\"id\", dtype=DataType.VARCHAR, is_primary=True, max_length=32, description=\"customized primary id\")\n",
    "        embedding_field = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=dim, description=\"vector embeddings for text\")\n",
    "        text_field = FieldSchema(name=\"text\", dtype=DataType.VARCHAR, description=\"abstract of document\", max_length=8192)\n",
    "        metadata_field = FieldSchema(name=\"metadata\", dtype=DataType.JSON)\n",
    "        nodeids_field = FieldSchema(name=\"node_ids\", dtype=DataType.ARRAY, element_type=DataType.VARCHAR, max_capacity=4096, max_length=32, description=\"node ids for each chunk in document\")\n",
    "        \n",
    "        schema = CollectionSchema(fields=[id_field, embedding_field, text_field, metadata_field, nodeids_field,],\n",
    "                                description=\"collection for Federal Register documents (documents)\")\n",
    "        print(f\"Creating example collection: {collection_name}\")\n",
    "        collection = Collection(name=collection_name, schema=schema)\n",
    "        connections.disconnect(\"default\")\n",
    "    else:\n",
    "        print(\"Collection name error!\")\n",
    "\n",
    "    return milvus_settings\n",
    "\n",
    "def upload_documents_by_json(json_data=None, json_path=None, collection_name='documents_FR', milvus_db=milvus_db_fr, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token, overwrite=False, dim=768, create_collection=False, dir_name=\"bge_base_onnx\", model_name=\"BAAI/bge-base-en-v1.5\"):\n",
    "    assert 'documents' in collection_name, \"collection name must be 'documents_FR'\"\n",
    "    assert json_data != None or json_path != None, \"json data or json path should be needed\"\n",
    "\n",
    "    if json_path is not None:\n",
    "        if 'document' in collection_name and 'document' not in os.path.basename(json_path):\n",
    "            print(\"data type of json file should match with collection type\")\n",
    "            return\n",
    "        with open(json_path) as f:\n",
    "            json_data = json.load(f)\n",
    "    \n",
    "    try:\n",
    "        connections.connect(\n",
    "            uri=milvus_uri,\n",
    "            token=milvus_token)\n",
    "    except:\n",
    "        print(f\"Failed to connect, please check MILVUS URI/TOKEN.\")\n",
    "        sys.exit()\n",
    "\n",
    "    check_collection = utility.has_collection(collection_name)\n",
    "    if not check_collection:\n",
    "        if create_collection:\n",
    "            connections.disconnect(\"default\")\n",
    "            creat_milvus_collection(collection_name, milvus_uri=milvus_uri, milvus_db=milvus_db, milvus_user=milvus_user, milvus_password=milvus_password, milvus_token=milvus_token, dim=dim, overwrite=overwrite)\n",
    "            connections.connect(\n",
    "                        uri=milvus_uri,\n",
    "                        token=f\"{milvus_user}:{milvus_password}\")\n",
    "        else:\n",
    "            print(f\"'{collection_name}' collection does not exist. Please create collection before upload\")\n",
    "            connections.disconnect(\"default\")\n",
    "            sys.exit()\n",
    "    \n",
    "    embed_class = embed_helper(dir_name=\"bge_base_onnx\", embed_path='model', model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "    embed_class.set_model()\n",
    "    \n",
    "    key_list = list(json_data.keys())\n",
    "    start_idx = 0\n",
    "    if \"document\" in collection_name:\n",
    "        result_list = [[],[],[],[],[]]\n",
    "\n",
    "    total_step = len(key_list) // 1024 + 1\n",
    "    present_step = 1\n",
    "    while start_idx < len(key_list):\n",
    "        print(f\"upload process: {present_step} / {total_step}\")\n",
    "        end_idx = min(start_idx + 1024, len(key_list))\n",
    "        if \"document\" in collection_name:\n",
    "            # id, embedding, text, metadata, node_ids\n",
    "            result_list = [[],[],[],[],[]]\n",
    "            for key in key_list[start_idx:end_idx]:\n",
    "                text = json_data[key]['summary']\n",
    "                truncated_text = embed_class.get_truncation(text)\n",
    "                embedding = embed_class.get_embedding(truncated_text)\n",
    "                result_list[0].append(json_data[key]['id'])\n",
    "                result_list[1].append(embedding)\n",
    "                result_list[2].append(json_data[key]['summary'])\n",
    "                result_list[3].append(json_data[key]['metadata'])\n",
    "                result_list[4].append(json_data[key]['nodeids'])\n",
    "            upload_documents_fr(result_list, collection_name=collection_name, milvus_uri=milvus_uri, milvus_token=milvus_token, overwrite=False)\n",
    "        present_step += 1\n",
    "        start_idx = end_idx\n",
    "    connections.disconnect(\"default\")\n",
    "\n",
    "# documentDB에서 검색된 json data( {id :{_id, metadata, text,}}) 를 가지고\n",
    "# collection_name, bookshelf_id를 받아서 업로드\n",
    "def upload_chunks_by_json(json_data, collection_name, bookshelf_id, milvus_db=milvus_db_fr, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token, overwrite=False, dim=768, create_collection=True, dir_name=\"bge_base_onnx\", model_name=\"openai\"):\n",
    "    assert 'chunks' in collection_name, \"collection name must contain 'chunks'\"\n",
    "    # 나중에 dimension 받아오기\n",
    "    embed_class = embed_helper(dir_name=dir_name, embed_path='model', model_name=model_name)\n",
    "    embed_class.set_model()\n",
    "\n",
    "    key_list = list(json_data.keys())\n",
    "    start_idx = 0\n",
    "\n",
    "    while start_idx < len(key_list):\n",
    "        end_idx = min(start_idx + 1024, len(key_list))\n",
    "\n",
    "        # id, embedding, text, metadata, node_ids\n",
    "        result_list = [[],[],[],[]]\n",
    "        for key in tqdm(key_list[start_idx:end_idx]):\n",
    "            text = json_data[key]['text']\n",
    "            # truncated_text = embed_class.get_truncation(text)\n",
    "            # embedding = embed_class.get_embedding(truncated_text)\n",
    "            # result_list[0].append(json_data[key]['_id'])\n",
    "            # result_list[1].append(embedding)\n",
    "            # result_list[2].append(json_data[key]['metadata'])\n",
    "            # result_list[3].append(json_data[key]['text'])\n",
    "            truncated_text = embed_class.get_truncation(text)\n",
    "            result_list[0].append(json_data[key]['_id'])\n",
    "            result_list[1].append(truncated_text)\n",
    "            result_list[2].append(json_data[key]['metadata'])\n",
    "            result_list[3].append(json_data[key]['text'])\n",
    "        tmp=[]\n",
    "        for i in  range(1, (len(result_list[1])//2000)+2):\n",
    "            tmp.extend(embed_class.get_embedding_test(result_list[1][(i-1)*2000:i*2000]))\n",
    "        result_list[1] = tmp\n",
    "        upload_chunks_fr(result_list, collection_name=collection_name, partition_name=bookshelf_id, milvus_uri=milvus_uri, milvus_token=milvus_token, overwrite=False)\n",
    "\n",
    "        start_idx = end_idx\n",
    "    \n",
    "def delete_chunks_by_json(document_list, collection_name, bookshelf_id, milvus_db=milvus_db_fr, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token, overwrite=False, dim=768):\n",
    "    assert 'chunks' in collection_name, \"collection name must contain 'chunks'\"\n",
    "    if not milvus_token:\n",
    "        milvus_token = f\"{milvus_user}:{milvus_password}\"\n",
    "    #connet to cluster\n",
    "    try:\n",
    "        connections.connect(\n",
    "            uri=milvus_uri,\n",
    "            token=milvus_token)\n",
    "        print(f\"Connect to DB: Success\")\n",
    "    except:\n",
    "        print(f\"Failed to connect, please check MILVUS URI/TOKEN.\")\n",
    "        sys.exit()\n",
    "    # check collection\n",
    "    check_collection = utility.has_collection(collection_name)\n",
    "    if not check_collection:\n",
    "        print(f\"'{collection_name}' collection does not exist. Please check collection name before delete data\")\n",
    "        connections.disconnect(\"default\")\n",
    "        sys.exit()\n",
    "    \n",
    "    expr_list = [f\"id like \\\"{doc_str}%\\\"\" for doc_str in document_list]\n",
    "    expr = \" or \".join(expr_list)\n",
    "    try:\n",
    "        partition = Partition(collection=collection_name, name=bookshelf_id)\n",
    "        partition.delete(\n",
    "                    expr=expr,\n",
    "                    partition_names=[bookshelf_id],\n",
    "                )\n",
    "    except:\n",
    "        print(\"failed to delete documents list\")\n",
    "\n",
    "    connections.disconnect(\"default\")\n",
    "    return\n",
    "\n",
    "# node_list 만들어서 \n",
    "def upload_chunks_fr(node_list, collection_name='chunks_FR', partition_name=None, milvus_db=milvus_db_fr, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token, overwrite=False, dim=768, create_collection=True):\n",
    "    assert ('chunks' in collection_name), \"only for uploading chunks\"\n",
    "    append_milvus_list = []\n",
    "    # connect to milvus cloud\n",
    "    if not milvus_token:\n",
    "        milvus_token = f\"{milvus_user}:{milvus_password}\"\n",
    "    try:\n",
    "        connections.connect(\n",
    "            uri=milvus_uri,\n",
    "            token=milvus_token)\n",
    "        print(f\"Connect to DB: Success\")\n",
    "    except:\n",
    "        print(f\"Failed to connect, please check MILVUS URI/TOKEN.\")\n",
    "        sys.exit()\n",
    "    # check and overwrite or quit\n",
    "    check_collection = utility.has_collection(collection_name)\n",
    "    if not check_collection:\n",
    "        if create_collection:\n",
    "            connections.disconnect(\"default\")\n",
    "            creat_milvus_collection(collection_name, milvus_uri=milvus_uri, milvus_db=milvus_db, milvus_user=milvus_user, milvus_password=milvus_password, milvus_token=milvus_token, dim=dim, overwrite=overwrite)\n",
    "            connections.connect(\n",
    "                        uri=milvus_uri,\n",
    "                        token=f\"{milvus_user}:{milvus_password}\")\n",
    "        else:\n",
    "            print(f\"'{collection_name}' collection does not exist. Please create collection before upload\")\n",
    "            connections.disconnect(\"default\")\n",
    "            sys.exit()\n",
    "        \n",
    "    print(f\"Connect to DB: Success\")\n",
    "    \n",
    "    collection = Collection(name=collection_name)\n",
    "    print(f\"Load '{collection_name}' Collection: Success!\")\n",
    "    \n",
    "    if partition_name != None:\n",
    "        has_partition = utility.has_partition(collection_name=collection_name, partition_name=partition_name)\n",
    "        if not has_partition:\n",
    "            collection.create_partition(partition_name=partition_name)\n",
    "            # later consider: index type\n",
    "            index_params = {\"index_type\": \"AUTOINDEX\", \"metric_type\": \"COSINE\", \"params\": {}}\n",
    "            collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "        # 삭제할 내용\n",
    "        ins_resp = collection.upsert(node_list, partition_name=partition_name)\n",
    "        \n",
    "        # 새로운 내용\n",
    "        new_node_list = [[], [], [], []]\n",
    "        bookshelf = Partition(collection=collection_name, name=partition_name)\n",
    "        bookshelf.load()\n",
    "        id_list = node_list[0]\n",
    "        expr = f\"id in {str(id_list)}\"\n",
    "        res = bookshelf.query(\n",
    "            expr=expr,\n",
    "            output_fields = [\"id\"]\n",
    "        )\n",
    "        for i in range(len(id_list)-1, -1, -1):\n",
    "            if id_list[i] in list(map(lambda k: k['id'], res)):\n",
    "                node_list[0].pop()\n",
    "                node_list[1].pop()\n",
    "                node_list[2].pop()\n",
    "                node_list[3].pop()\n",
    "            else:\n",
    "                a = node_list[0].pop()\n",
    "                b = node_list[1].pop()\n",
    "                c = node_list[2].pop()\n",
    "                d = node_list[3].pop()\n",
    "                new_node_list[0].append(a)\n",
    "                new_node_list[1].append(b)\n",
    "                new_node_list[2].append(c)\n",
    "                new_node_list[3].append(d)\n",
    "        ins_resp = collection.insert(new_node_list)\n",
    "    else:\n",
    "        ins_resp = collection.upsert(new_node_list)\n",
    "    #print([type(e[0]) for e in entities])\n",
    "    \"\"\"for entity in entities:\n",
    "        ins_resp = collection.insert(entities)\"\"\"\n",
    "        #print(f\"Succeed insert {inserted_data} data!\")\n",
    "\n",
    "    print(\"flush start!\")\n",
    "    collection.flush()\n",
    "    print(\"flush done!\")\n",
    "    connections.disconnect(\"default\")\n",
    "    # already_milvus update\n",
    "    try:\n",
    "        with open(already_milvus, 'r') as f:\n",
    "            exist_milvus = json.load(f)\n",
    "    except:\n",
    "        exist_milvus = {'chunks':[], 'documents':[]}\n",
    "    with open(already_milvus, 'w') as f:\n",
    "        exist_milvus['chunks'] = exist_milvus['chunks'] + append_milvus_list\n",
    "        json.dump(exist_milvus, f)\n",
    "\n",
    "def upload_documents_fr(node_list, collection_name='documents_FR', milvus_db=milvus_db_fr, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token, overwrite=False, dim=768, create_collection=True):\n",
    "    assert ('documents' in collection_name), \"only for uploading documents\"\n",
    "    append_milvus_list = []\n",
    "    # connect to milvus cloud\n",
    "    if not milvus_token:\n",
    "        milvus_token = f\"{milvus_user}:{milvus_password}\"\n",
    "    try:\n",
    "        connections.connect(\n",
    "            uri=milvus_uri,\n",
    "            token=milvus_token)\n",
    "        print(f\"Connect to DB: Success\")\n",
    "    except:\n",
    "        print(f\"Failed to connect, please check MILVUS URI/TOKEN.\")\n",
    "        sys.exit()\n",
    "    # check and overwrite or quit\n",
    "    check_collection = utility.has_collection(collection_name)\n",
    "    if not check_collection:\n",
    "        if create_collection:\n",
    "            connections.disconnect(\"default\")\n",
    "            creat_milvus_collection(collection_name, milvus_db=milvus_db, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token, dim=dim, overwrite=overwrite)\n",
    "            connections.connect(\n",
    "                        uri=milvus_uri,\n",
    "                        token=f\"{milvus_user}:{milvus_password}\")\n",
    "        else:\n",
    "            print(f\"'{collection_name}' collection does not exist. Please create collection before upload\")\n",
    "            connections.disconnect(\"default\")\n",
    "            sys.exit()\n",
    "        \n",
    "    print(f\"Connect to DB: Success\")\n",
    "    \n",
    "    collection = Collection(name=collection_name)\n",
    "    print(f\"Load '{collection_name}' Collection: Success!\")\n",
    "    \n",
    "    \n",
    "    #ins_resp = collection.insert(entities)\n",
    "    ins_resp = collection.upsert(node_list)\n",
    "        \n",
    "    #print([type(e[0]) for e in entities])\n",
    "    \"\"\"for entity in entities:\n",
    "        ins_resp = collection.insert(entities)\"\"\"\n",
    "    \n",
    "    #print(f\"Succeed insert {inserted_data} data!\")\n",
    "\n",
    "    print(\"flush start!\")\n",
    "    collection.flush()\n",
    "\n",
    "    # later consider: index type\n",
    "    index_params = {\"index_type\": \"AUTOINDEX\", \"metric_type\": \"COSINE\", \"params\": {}}\n",
    "    collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "    print(\"flush done!\")\n",
    "\n",
    "    connections.disconnect(\"default\")\n",
    "\n",
    "    # already_milvus update\n",
    "    try:\n",
    "        with open(already_milvus, 'r') as f:\n",
    "            exist_milvus = json.load(f) # // dict('chunks', 'documents')\n",
    "    except:\n",
    "        exist_milvus = {'chunks':[], 'documents':[]}\n",
    "    with open(already_milvus, 'w') as f:\n",
    "        exist_milvus['documents'] = exist_milvus['documents'] + append_milvus_list\n",
    "        json.dump(exist_milvus, f)\n",
    "\n",
    "# 유저가 검색해서 document_\n",
    "# node_ids 받아서 검색\n",
    "# node_ids 는 bookshelf에 들어간 \n",
    "\n",
    "\n",
    "def find_chunkid_expr(collection_name, element_list, query_expr, milvus_db=milvus_db_fr, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token):\n",
    "    assert \"chunks\" in collection_name, \"Find the document just only for chunks collections\"\n",
    "    # eg. query_expr = r'metadata[\"document_number\"] == \"{ele}\"'\n",
    "    if not milvus_token:\n",
    "        milvus_token = f\"{milvus_user}:{milvus_password}\"\n",
    "    try:\n",
    "        connections.connect(\n",
    "            uri=milvus_uri,\n",
    "            token=milvus_token)\n",
    "        print(f\"Connect to DB: Success\")\n",
    "    except:\n",
    "        print(f\"Failed to connect, please check MILVUS URI/TOKEN.\")\n",
    "        sys.exit()\n",
    "    # check and overwrite or quit\n",
    "    check_collection = utility.has_collection(collection_name)\n",
    "    if not check_collection:\n",
    "        print(f\"{collection_name} collection does not exists\")\n",
    "        connections.disconnect(\"default\")\n",
    "        sys.exit()\n",
    "    collection = Collection(name=collection_name)\n",
    "    print(\"Load Collection: Success!\")\n",
    "    \n",
    "    result_ids = []\n",
    "    tried_doc = 0\n",
    "    for ele in element_list:\n",
    "        try:\n",
    "            res = collection.query(\n",
    "                expr=re.sub(r\"{ele}\", ele, query_expr),\n",
    "                output_fields=['id'],\n",
    "            )\n",
    "            tried_doc += 1\n",
    "        except:\n",
    "            print(f\"try number: {tried_doc}\")\n",
    "            print(ele)\n",
    "            sys.exit()\n",
    "        if len(res) > 0:\n",
    "            result_ids.extend(res)\n",
    "    result_ids = [result['id'] for result in result_ids]\n",
    "    print(\"Done with verifying existing documents\")\n",
    "    #print(f\"{exist_doc} already exist in milvus DB\")\n",
    "    return result_ids\n",
    "\n",
    "def find_partitions(collection_name, milvus_db=milvus_db_fr, milvus_user=milvus_user, milvus_password=milvus_password, milvus_uri=milvus_uri, milvus_token=milvus_token, stringify=True):\n",
    "    connections.connect(\n",
    "        uri=milvus_uri,\n",
    "        token=milvus_token)\n",
    "    check_collection = utility.has_collection(collection_name)\n",
    "    if not check_collection:\n",
    "        print(f\"{collection_name} collection does not exists\")\n",
    "        connections.disconnect(\"default\")\n",
    "        sys.exit()\n",
    "    collection = Collection(name=collection_name)\n",
    "    if stringify:\n",
    "        temp_conn = collection._get_connection()\n",
    "        partitions = temp_conn.list_partitions(collection_name)\n",
    "    else:\n",
    "        partitions = collection.partitions\n",
    "    return partitions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
